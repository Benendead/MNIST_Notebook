{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Keras and CNNs",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [
        "N9-Cvgxi0IjF",
        "KGqvrtae0PXl",
        "E7TbNPJEyuk4",
        "IyBy4tkJ-xFj"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "kLLfMFZE8aP8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Classifying the MNIST dataset using Keras and CNNs\n",
        "*Compiled by Benned Hedegaard*\n",
        "\n",
        "In this notebook, we'll build a convolutional neural network using Keras, train our model to recognize handwritten digits, and then submit the results to a Kaggle competition using the MNIST dataset.\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1WKCNAtIpJ_0Cmyhn-jAFS9KSCcDUX5H1#scrollTo=kLLfMFZE8aP8&uniqifier=1)"
      ]
    },
    {
      "metadata": {
        "id": "N9-Cvgxi0IjF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import everything we'll need"
      ]
    },
    {
      "metadata": {
        "id": "dD8cbHHPWpvY",
        "colab_type": "code",
        "outputId": "be785028-999c-4b34-f505-6e7d088d3369",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Imports everything we'll need. \n",
        "# Typically, Colab already has these imported but I've kept these here so that it's clear what we're using.\n",
        "\n",
        "import keras\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "# np.random.seed(7007)  # for reproducibility"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "EtU3m4WWWpvk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Can create a linear stack of layers.\n",
        "from keras.models import Sequential\n",
        "# Basically the core layers of any neural network.\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "# Specifically CNN layers.\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "# Useful utilities\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OqH-MszLWpvn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "This example creates a sequential model with a single dense layer with 10 outputs. Note that we need \n",
        "to specify the input shape.\n",
        "\"\"\"\n",
        "m = Sequential([Dense(10, input_shape = (10,)), Activation('linear') ])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kr5rFPbOWpvq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "We also need to compile a Keras model. This sets up importantparts like its optimizer, loss function, \n",
        "and the metrics by which we measure the model's success.\n",
        "\"\"\"\n",
        "m.compile(optimizer = 'rmsprop', loss = 'mse', metrics = ['mse', 'mae'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VhnHVD3bWpvv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A much more elegant way to import the MNIST dataset, but not for Kaggle submissions.\n",
        "Loads in the MNIST dataset:\n",
        "\n",
        "from keras.datasets import mnist\n",
        "\n",
        "(X_train, Y_train), (X_test, Y_test) = mnist.load_data()"
      ]
    },
    {
      "metadata": {
        "id": "nsY4eFqIZui3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "bc9f9e2f-de89-47eb-ed0a-246dbb8c654e"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q xlrd\n",
        "!git clone https://github.com/Benendead/MNIST_Notebook/"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'MNIST_Notebook'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 28 (delta 7), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fHJamdm1pqVm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e32c8bae-b0fb-40fd-9cc0-d37cc5eea433"
      },
      "cell_type": "code",
      "source": [
        "!ls MNIST_Notebook/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 30_epochs   dataset.zip  'Keras and CNNs (3).ipynb'   README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "07Hu3mu1u0uW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        },
        "outputId": "51fcfa8b-58c2-464f-b0bd-5079756e6781"
      },
      "cell_type": "code",
      "source": [
        "# Open up the .zip file containing our dataset.\n",
        "!unzip MNIST_Notebook/dataset.zip"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  MNIST_Notebook/dataset.zip\n",
            "   creating: dataset/\n",
            "  inflating: dataset/test.csv        \n",
            "   creating: __MACOSX/\n",
            "   creating: __MACOSX/dataset/\n",
            "  inflating: __MACOSX/dataset/._test.csv  \n",
            "  inflating: dataset/train.csv       \n",
            "  inflating: __MACOSX/dataset/._train.csv  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ObtbGt8fu5V-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7df3ec3-c3cb-45bc-e555-8cc942d2755e"
      },
      "cell_type": "code",
      "source": [
        "# There it is.\n",
        "!ls dataset/"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test.csv  train.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "8b3hYdMmWpvx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# This reads in the .csv files we've imported and uncompressed from Github.\n",
        "# The test variable here is a pandas DataFrame.\n",
        "train = pd.read_csv(\"dataset/train.csv\")\n",
        "test = pd.read_csv(\"dataset/test.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KGqvrtae0PXl",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "metadata": {
        "id": "1JWefjHjWpv0",
        "colab_type": "code",
        "outputId": "57dfbc1d-d53c-40ab-8db7-d63d6823abdf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "cell_type": "code",
      "source": [
        "# Previews the imported data. Right now every image is one row. \n",
        "# We need to fix that.\n",
        "train.head(3)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>pixel0</th>\n",
              "      <th>pixel1</th>\n",
              "      <th>pixel2</th>\n",
              "      <th>pixel3</th>\n",
              "      <th>pixel4</th>\n",
              "      <th>pixel5</th>\n",
              "      <th>pixel6</th>\n",
              "      <th>pixel7</th>\n",
              "      <th>pixel8</th>\n",
              "      <th>...</th>\n",
              "      <th>pixel774</th>\n",
              "      <th>pixel775</th>\n",
              "      <th>pixel776</th>\n",
              "      <th>pixel777</th>\n",
              "      <th>pixel778</th>\n",
              "      <th>pixel779</th>\n",
              "      <th>pixel780</th>\n",
              "      <th>pixel781</th>\n",
              "      <th>pixel782</th>\n",
              "      <th>pixel783</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows Ã— 785 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
              "0      1       0       0       0       0       0       0       0       0   \n",
              "1      0       0       0       0       0       0       0       0       0   \n",
              "2      1       0       0       0       0       0       0       0       0   \n",
              "\n",
              "   pixel8    ...     pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
              "0       0    ...            0         0         0         0         0   \n",
              "1       0    ...            0         0         0         0         0   \n",
              "2       0    ...            0         0         0         0         0   \n",
              "\n",
              "   pixel779  pixel780  pixel781  pixel782  pixel783  \n",
              "0         0         0         0         0         0  \n",
              "1         0         0         0         0         0  \n",
              "2         0         0         0         0         0  \n",
              "\n",
              "[3 rows x 785 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "6Kv18SUfWpv5",
        "colab_type": "code",
        "outputId": "e1349a55-8d48-447f-cb89-fd283994614e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# We now put the datasets into numpy arrays.\n",
        "np_train = train.values\n",
        "np_test = test.values\n",
        "\n",
        "# Prints out the shape and type of the training set dataframe.\n",
        "print(np_train.shape)\n",
        "print(type(np_train))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 785)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HfXLXVY0Wpv9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c582fa38-3d83-4fd0-d3a7-6bbd380b11ab"
      },
      "cell_type": "code",
      "source": [
        "# These format the arrays so that the images are now grids instead of rows.\n",
        "# We also extract the labels for the training data as Y_train.\n",
        "\n",
        "X_train = np_train[:,1:]\n",
        "X_train = np.reshape(X_train, (len(X_train), 28, 28))\n",
        "Y_train = np_train[:,0]\n",
        "\n",
        "print(\"Shape of np_test:\", np_test.shape)\n",
        "X_test = np.reshape(np_test, (len(np_test), 28, 28, 1)) # Change the dimensions because that's what our Keras model wants.\n",
        "print(\"Shape of X_test:\", X_test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of np_test: (28000, 784)\n",
            "Shape of X_test: (28000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GXNnnbi5WpwA",
        "colab_type": "code",
        "outputId": "4c95601b-e73f-4d92-a536-f8162a9625d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "# 42,000 training examples. Each one is a 28 by 28 grid."
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 28, 28)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "YqXm-XuaWpwE",
        "colab_type": "code",
        "outputId": "84ea75f3-1594-4f63-f6f1-2c9f26b65e80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# This works as one might expect.\n",
        "print(len(X_train))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "VTknQCbdWpwM",
        "colab_type": "code",
        "outputId": "aecf8950-1d2a-4130-fbbf-33c420eeac77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        }
      },
      "cell_type": "code",
      "source": [
        "# Randomly plots four examples from the training data.\n",
        "# Also prints their labels from the training data labels.\n",
        "fig, axes = plt.subplots(nrows = 2, ncols = 2)\n",
        "nums = []\n",
        "for i in range(4):\n",
        "    num = np.random.randint(0, len(X_train))\n",
        "    nums.append(num)\n",
        "\n",
        "# Removes ticks from all 4 subplots in one line.\n",
        "plt.setp(axes, xticks = [], yticks = [])\n",
        "    \n",
        "k = 0\n",
        "for i in range(2):\n",
        "    for j in range(2):\n",
        "        axes[i,j].imshow(X_train[nums[k]])\n",
        "        k += 1\n",
        "\n",
        "print(Y_train[nums[0]], Y_train[nums[1]])\n",
        "print(Y_train[nums[2]], Y_train[nums[3]])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4 9\n",
            "4 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAE5CAYAAABlF9zIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7fc7df5226a0>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "ynDvOMTpWpwR",
        "colab_type": "code",
        "outputId": "dc3a8636-c17d-431f-d4ec-7f4c6afb8ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        }
      },
      "cell_type": "code",
      "source": [
        "# This shows what the data actually looks like to the machine.\n",
        "index = 1\n",
        "print(Y_train[index])\n",
        "pd.DataFrame(X_train[index])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>86</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>16</td>\n",
              "      <td>179</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>231</td>\n",
              "      <td>54</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>72</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>104</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>61</td>\n",
              "      <td>191</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>243</td>\n",
              "      <td>85</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>172</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>174</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>89</td>\n",
              "      <td>...</td>\n",
              "      <td>252</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>212</td>\n",
              "      <td>76</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>47</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>83</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>80</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>240</td>\n",
              "      <td>24</td>\n",
              "      <td>...</td>\n",
              "      <td>25</td>\n",
              "      <td>240</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>153</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>64</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>186</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>166</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>224</td>\n",
              "      <td>12</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14</td>\n",
              "      <td>232</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>75</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>18</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>163</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>48</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>17</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>94</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>200</td>\n",
              "      <td>...</td>\n",
              "      <td>16</td>\n",
              "      <td>209</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>150</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>15</td>\n",
              "      <td>206</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>161</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>245</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>212</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>171</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>86</td>\n",
              "      <td>243</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>254</td>\n",
              "      <td>86</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>114</td>\n",
              "      <td>254</td>\n",
              "      <td>...</td>\n",
              "      <td>254</td>\n",
              "      <td>239</td>\n",
              "      <td>86</td>\n",
              "      <td>11</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>13</td>\n",
              "      <td>182</td>\n",
              "      <td>...</td>\n",
              "      <td>243</td>\n",
              "      <td>70</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>...</td>\n",
              "      <td>15</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>28 rows Ã— 28 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    0   1   2   3   4    5    6    7    8    9  ...   18   19   20   21   22  \\\n",
              "0    0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "1    0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "2    0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "3    0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "4    0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "5    0   0   0   0   0    0    0    0   13   86 ...   32    0    0    0    0   \n",
              "6    0   0   0   0   0    0    0   16  179  254 ...  231   54   15    0    0   \n",
              "7    0   0   0   0   0    0    0   72  254  254 ...  254  254  104    0    0   \n",
              "8    0   0   0   0   0    0   61  191  254  254 ...  254  254  243   85    0   \n",
              "9    0   0   0   0   0    0  172  254  254  254 ...  254  254  254  171    0   \n",
              "10   0   0   0   0   0    1  174  254  254   89 ...  252  254  254  212   76   \n",
              "11   0   0   0   0   0   47  254  254  254   29 ...   83  254  254  254  153   \n",
              "12   0   0   0   0   0   80  254  254  240   24 ...   25  240  254  254  153   \n",
              "13   0   0   0   0   0   64  254  254  186    7 ...    0  166  254  254  224   \n",
              "14   0   0   0   0  14  232  254  254  254   29 ...    0   75  254  254  254   \n",
              "15   0   0   0   0  18  254  254  254  254   29 ...    0   48  254  254  254   \n",
              "16   0   0   0   0   2  163  254  254  254   29 ...    0   48  254  254  254   \n",
              "17   0   0   0   0   0   94  254  254  254  200 ...   16  209  254  254  150   \n",
              "18   0   0   0   0   0   15  206  254  254  254 ...  161  254  254  245   31   \n",
              "19   0   0   0   0   0    0   60  212  254  254 ...  254  254  254  171    0   \n",
              "20   0   0   0   0   0    0    0   86  243  254 ...  254  254  254   86    0   \n",
              "21   0   0   0   0   0    0    0    0  114  254 ...  254  239   86   11    0   \n",
              "22   0   0   0   0   0    0    0    0   13  182 ...  243   70    0    0    0   \n",
              "23   0   0   0   0   0    0    0    0    0    8 ...   15    0    0    0    0   \n",
              "24   0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "25   0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "26   0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "27   0   0   0   0   0    0    0    0    0    0 ...    0    0    0    0    0   \n",
              "\n",
              "    23  24  25  26  27  \n",
              "0    0   0   0   0   0  \n",
              "1    0   0   0   0   0  \n",
              "2    0   0   0   0   0  \n",
              "3    0   0   0   0   0  \n",
              "4    0   0   0   0   0  \n",
              "5    0   0   0   0   0  \n",
              "6    0   0   0   0   0  \n",
              "7    0   0   0   0   0  \n",
              "8    0   0   0   0   0  \n",
              "9    0   0   0   0   0  \n",
              "10   0   0   0   0   0  \n",
              "11   0   0   0   0   0  \n",
              "12   0   0   0   0   0  \n",
              "13  12   0   0   0   0  \n",
              "14  17   0   0   0   0  \n",
              "15  17   0   0   0   0  \n",
              "16  17   0   0   0   0  \n",
              "17   1   0   0   0   0  \n",
              "18   0   0   0   0   0  \n",
              "19   0   0   0   0   0  \n",
              "20   0   0   0   0   0  \n",
              "21   0   0   0   0   0  \n",
              "22   0   0   0   0   0  \n",
              "23   0   0   0   0   0  \n",
              "24   0   0   0   0   0  \n",
              "25   0   0   0   0   0  \n",
              "26   0   0   0   0   0  \n",
              "27   0   0   0   0   0  \n",
              "\n",
              "[28 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "metadata": {
        "id": "pqxdeScgWpwW",
        "colab_type": "code",
        "outputId": "f5f2474b-64c3-4898-ffd8-6c0d39a0ed09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# We need to format the data into the description:\n",
        "#              n, depth, width, height.\n",
        "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "print(X_train.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 28, 28, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ir385kZpWpwb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# It's also wise to standardize the data type as float32.\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L8iwSoujWpwg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Finally, we should normalize the data to the range [0,1]. It started 0 to 255, so this should do the trick.\n",
        "X_train /= 255\n",
        "X_test /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xgndf8HgWpwk",
        "colab_type": "code",
        "outputId": "9547d685-d2e3-43d4-e55b-caa129e1d26d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# We want a separate vector for each possible label. Right now we have a bunch of actual labels.\n",
        "# That's no good.\n",
        "print(Y_train.shape)\n",
        "print(Y_train[:10]) # Peeps the first 10 elements of Y-train."
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000,)\n",
            "[1 0 1 4 0 0 7 3 5 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qDAKWbJyWpzI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Turns each possible label into a binary vector. Look up \"one hot encoding\" for more info\n",
        "Y_train = np_utils.to_categorical(Y_train, 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5BrDblylWpzL",
        "colab_type": "code",
        "outputId": "e0451113-f3ed-4c65-9c2f-43b3fac5a228",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# This is better.\n",
        "print(Y_train.shape)\n",
        "print(Y_train[:10]) # Now each label is a vector of the ten possible options."
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(42000, 10)\n",
            "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E7TbNPJEyuk4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Creating the Convolutional Neural Network"
      ]
    },
    {
      "metadata": {
        "id": "Uo_asKDyWpzQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Moving right along, let's establish our model.\n",
        "model = Sequential()\n",
        "\n",
        "# We also add the first layer, the input layer.\n",
        "model.add(Conv2D(32, (3, 3), strides = (1, 1), \n",
        "                 activation = \"relu\", input_shape = (28, 28, 1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X-6baLtA0eK8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Format of the Conv2D arguments**\n",
        "\n",
        "filters : integer\n",
        "\n",
        "kernal_size : tuple\n",
        "\n",
        "strides : tuple (optional, default is (1,1))\n",
        "\n",
        "activation : String\n",
        "\n",
        "*Options include softmax, elu, relu, softplus, softsign, tanh, sigmoid, and more.*\n",
        "    \n",
        "input_shape : tuple (Conv2D expects a 3-tuple)"
      ]
    },
    {
      "metadata": {
        "id": "75ASv_t-WpzU",
        "colab_type": "code",
        "outputId": "f2b6c7f2-50bb-4f41-c032-53fa9be1104f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# Allows us to check the shape of the output of our model.\n",
        "print(model.output_shape)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 26, 26, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6cXORvauWpzZ",
        "colab_type": "code",
        "outputId": "9d7dbf28-f586-41db-8a0d-c233863f359c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32, (3, 3), activation = 'relu')) # The first hidden layer.\n",
        "model.add(MaxPooling2D(pool_size = (2, 2))) # The first pooling layer. \n",
        "model.add(Dropout(0.25)) # First dropout layer.\n",
        "print(model.output_shape) # Then check our output's shape."
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 12, 12, 32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sWyhasfPWpzf",
        "colab_type": "code",
        "outputId": "52d831de-c633-4ce0-9b21-6c9b670207c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(16, (2, 2), activation = \"relu\")) # The second hidden layer.\n",
        "model.add(Dropout(0.15)) # Second dropout layer.\n",
        "print(model.output_shape) # Then check our shape."
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 11, 11, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X5K6lPWWWpzj",
        "colab_type": "code",
        "outputId": "f4f9aa8b-b67b-459c-eab3-0667b60fdcb7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "# The Flatten layer merges all filters together.\n",
        "model.add(Flatten())\n",
        "print(model.output_shape)\n",
        "print(11*11*16)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(None, 1936)\n",
            "1936\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "auTNd1oGWpzn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# We add a fully connected layer, dropout one last time, and then have our final layer.\n",
        "model.add(Dense(128, activation = \"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation = \"sigmoid\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "A3Bku5FsWpzq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Once we have all our layers, we can compile the model.\n",
        "# The metrics argument allows us to specify different metrics for different outputs.\n",
        "model.compile(loss = \"categorical_crossentropy\",\n",
        "              optimizer = \"adam\",\n",
        "              metrics = [\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IyBy4tkJ-xFj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training and testing"
      ]
    },
    {
      "metadata": {
        "id": "jUPXQ2sfWpzt",
        "colab_type": "code",
        "outputId": "46c13dcc-eb05-40de-d5d7-d3532f7e891f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "cell_type": "code",
      "source": [
        "# Trains the model for a given number of epochs. Takes about a minute and a half if we're on Colab's GPU. Any questions?\n",
        "model.fit(X_train, Y_train, \n",
        "          batch_size = 32, epochs = 5, verbose = 1)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "42000/42000 [==============================] - 19s 452us/step - loss: 0.3352 - acc: 0.9023\n",
            "Epoch 2/5\n",
            "42000/42000 [==============================] - 15s 361us/step - loss: 0.1173 - acc: 0.9652\n",
            "Epoch 3/5\n",
            "42000/42000 [==============================] - 15s 361us/step - loss: 0.0875 - acc: 0.9738\n",
            "Epoch 4/5\n",
            "42000/42000 [==============================] - 15s 360us/step - loss: 0.0752 - acc: 0.9769\n",
            "Epoch 5/5\n",
            "42000/42000 [==============================] - 15s 360us/step - loss: 0.0646 - acc: 0.9795\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fc7df471c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "metadata": {
        "id": "V4JUl4G32DtM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " **Format of the model.fit arguments**\n",
        "\n",
        "batch_size determines how many samples to use for each gradient update.\n",
        "\n",
        "epochs is the number of epochs to train the model. Each epoch is an iteration over the entire X, Y sets.\n",
        "\n",
        "verbose has three possible settings:\n",
        "* *0 would be silent.*\n",
        "* *1 would be a progress bar.*\n",
        "* *2 would be a message for each epoch.*"
      ]
    },
    {
      "metadata": {
        "id": "1Yt4tecsWpzy",
        "colab_type": "code",
        "outputId": "e3d30182-fefa-40cb-a0a1-70bdb6c96a75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# This evaluates the model on the training data. \n",
        "# We have no test data from Kaggle, so this is the next best thing.\n",
        "score = model.evaluate(X_train, Y_train, verbose = 1)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42000/42000 [==============================] - 5s 109us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Iwh0vYN3Wpz4",
        "colab_type": "code",
        "outputId": "2131d997-a63c-4077-c6a3-f58131d963ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# These are the loss and accuracy values. Ask someone who knows what they're doing what that means.\n",
        "score"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.02213823351506809, 0.9929523809523809]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "vgyDcjAIWpz8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Up to this point in the notebook, this article was the main source I used:\n",
        "\n",
        "https://elitedatascience.com/keras-tutorial-deep-learning-in-python#step-1"
      ]
    },
    {
      "metadata": {
        "id": "QIsT4AorWpz8",
        "colab_type": "code",
        "outputId": "3938895b-7f3e-4048-f146-2eb419e0eb96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Creates a numpy array of our algorithm's predictions on the test dataset.\n",
        "predictions = model.predict_classes(X_test, verbose = 1)\n",
        "print(predictions.shape)\n",
        "print(type(predictions))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28000/28000 [==============================] - 3s 90us/step\n",
            "(28000,)\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "o7nASqfCWp0B",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# And then this exports our predictions to a csv file.\n",
        "# Note that the submission suggestion was 1-indexed. Ugh.\n",
        "df = pd.DataFrame({\"ImageId\" : range(1,len(predictions) + 1),\n",
        "                   \"Label\" : predictions})\n",
        "df.to_csv(\"predictions.csv\", index = False)\n",
        "\n",
        "# We could then submit that .csv to the Kaggle competition."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H4qXSGnD-3Nv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Saving/loading a Keras model"
      ]
    },
    {
      "metadata": {
        "id": "Hqbr5XBDWp0D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Beyond all of that testing and training, we want the ability to save what our model has learned so far.\n",
        "\n",
        "I had a source for the initial method I used to do this, but I ended up just reading Keras' documentation and found a better way to save models."
      ]
    },
    {
      "metadata": {
        "id": "nOo6czOYWp0E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da3a4484-9553-41db-c649-aeba2641931c"
      },
      "cell_type": "code",
      "source": [
        "import h5py # Just in case.\n",
        "\n",
        "def saveModel(model, fileName):\n",
        "    \"\"\"\n",
        "    Saves a given Keras model into a .h5 file.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    model : Keras model\n",
        "        The model to be saved.\n",
        "    fileName : String\n",
        "        The main name of the files.\n",
        "    \"\"\"\n",
        "    # Save model to HDF5\n",
        "    h5_string = fileName + \".h5\"\n",
        "    model.save(h5_string)\n",
        "    print(\"Saved model to disk\")\n",
        "    \n",
        "saveModel(model, \"model_one\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "PI7UnOXbWp0G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def loadModel(filePath):\n",
        "    \"\"\"\n",
        "    Loads a given Keras model from a filepath.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    filePath : String\n",
        "        The path to the file.\n",
        "    \"\"\"\n",
        "    loaded_model = keras.models.load_model(filePath)\n",
        "    print(\"Loaded model from disk\")\n",
        "    return loaded_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L2_SY6kn4Vrb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9dc8ee5d-35a5-49eb-c1be-ea9b41457b39"
      },
      "cell_type": "code",
      "source": [
        "!ls MNIST_Notebook/"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " 30_epochs   dataset.zip  'Keras and CNNs (3).ipynb'   README.md\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7d8beh1L2oMR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7aabb0a1-15db-427a-9ae4-cfacfcb95e74"
      },
      "cell_type": "code",
      "source": [
        "# Let's load in a pre-trained model from my Github.\n",
        "new_model = loadModel(\"MNIST_Notebook/fifty_epochs.h5\")"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded model from disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "sdlV2AD1Wp0J",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "new_model.compile(loss = \"categorical_crossentropy\", optimizer = \"adam\", metrics = [\"accuracy\"])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_PRZxOVWp0O",
        "colab_type": "code",
        "outputId": "aa64c3b2-500d-46e1-8ae4-794d661e63a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "cell_type": "code",
      "source": [
        "new_model.fit(X_train, Y_train, \n",
        "              batch_size = 32, epochs = 1, verbose = 1)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "42000/42000 [==============================] - 21s 508us/step - loss: 0.0224 - acc: 0.9932\n",
            "Epoch 2/20\n",
            "42000/42000 [==============================] - 24s 570us/step - loss: 0.0210 - acc: 0.9936\n",
            "Epoch 3/20\n",
            "42000/42000 [==============================] - 25s 585us/step - loss: 0.0201 - acc: 0.9941\n",
            "Epoch 4/20\n",
            "42000/42000 [==============================] - 24s 572us/step - loss: 0.0208 - acc: 0.9935\n",
            "Epoch 5/20\n",
            "42000/42000 [==============================] - 24s 570us/step - loss: 0.0200 - acc: 0.9935\n",
            "Epoch 6/20\n",
            "42000/42000 [==============================] - 25s 596us/step - loss: 0.0186 - acc: 0.9942\n",
            "Epoch 7/20\n",
            "42000/42000 [==============================] - 25s 591us/step - loss: 0.0190 - acc: 0.9945\n",
            "Epoch 8/20\n",
            "42000/42000 [==============================] - 25s 584us/step - loss: 0.0177 - acc: 0.9944\n",
            "Epoch 9/20\n",
            "42000/42000 [==============================] - 25s 594us/step - loss: 0.0191 - acc: 0.9939\n",
            "Epoch 10/20\n",
            "42000/42000 [==============================] - 25s 597us/step - loss: 0.0156 - acc: 0.9951\n",
            "Epoch 11/20\n",
            "42000/42000 [==============================] - 25s 602us/step - loss: 0.0206 - acc: 0.9940\n",
            "Epoch 12/20\n",
            "42000/42000 [==============================] - 26s 610us/step - loss: 0.0180 - acc: 0.9940\n",
            "Epoch 13/20\n",
            "42000/42000 [==============================] - 23s 546us/step - loss: 0.0190 - acc: 0.9945\n",
            "Epoch 14/20\n",
            "42000/42000 [==============================] - 19s 462us/step - loss: 0.0164 - acc: 0.9952\n",
            "Epoch 15/20\n",
            "42000/42000 [==============================] - 19s 462us/step - loss: 0.0185 - acc: 0.9944\n",
            "Epoch 16/20\n",
            "42000/42000 [==============================] - 19s 458us/step - loss: 0.0177 - acc: 0.9944\n",
            "Epoch 17/20\n",
            "42000/42000 [==============================] - 18s 422us/step - loss: 0.0182 - acc: 0.9945\n",
            "Epoch 18/20\n",
            "42000/42000 [==============================] - 18s 424us/step - loss: 0.0178 - acc: 0.9948\n",
            "Epoch 19/20\n",
            "42000/42000 [==============================] - 18s 440us/step - loss: 0.0156 - acc: 0.9950\n",
            "Epoch 20/20\n",
            "42000/42000 [==============================] - 19s 456us/step - loss: 0.0162 - acc: 0.9948\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f81be49f9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "metadata": {
        "id": "issKoA0AWp0T",
        "colab_type": "code",
        "outputId": "81b8bd1c-fd7b-4ba7-f6e0-f2309835cf32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "score = new_model.evaluate(X_train, Y_train, verbose = 1)\n",
        "score"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "42000/42000 [==============================] - 5s 112us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.0023064056787046477, 0.9994761904761905]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "WPbbJlrP6SoH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As a note:\n",
        "\n",
        "* The test accuracy was 0.9994761904761905 after 30 epochs.\n",
        "* It was 0.9996428571428572 after 50 epochs, with a lot of fluctuation."
      ]
    },
    {
      "metadata": {
        "id": "Oh6RylOdWp0c",
        "colab_type": "code",
        "outputId": "0ed59db2-03c8-42a2-a3ea-d32b26f16b74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "saveModel(new_model, \"fiftyone_epochs\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved model to disk\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2Gg_wcJS6nvu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "15e11f88-687d-4569-866a-a97da62fc70b"
      },
      "cell_type": "code",
      "source": [
        "# Let's see if a new file is there.\n",
        "!ls"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dataset\t\t __MACOSX\t model_one.h5\t  sample_data\n",
            "fifty_epochs.h5  MNIST_Notebook  predictions.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HC2mA6WQ5Jd5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download(\"fiftyone_epochs.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wUpo78KkWp0g",
        "colab_type": "code",
        "outputId": "f2dd618f-6ee8-4e7c-82f1-990768516137",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "# This creates the .csv of our new preditions.\n",
        "\n",
        "predictions = new_model.predict_classes(X_test, verbose = 1)\n",
        "df = pd.DataFrame({\"ImageId\" : range(1,len(predictions) + 1),\n",
        "                   \"Label\" : predictions})\n",
        "df.to_csv(\"51_epochs.csv\", index = False)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "28000/28000 [==============================] - 3s 93us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Cm8gYCgz8BpG",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "files.download(\"51_epochs.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "K4FzH7NvWp0k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "As one last thing, the command to submit a csv file to Kaggle is:\n",
        "\n",
        "kaggle competitions submit -c digit-recognizer -f filepath/etc/submission.csv -m \"This is my message.\""
      ]
    }
  ]
}